# Assignment-0--Data-Basics-GitHub-and-Pull-requests-

The data set I analyzed was a Netflix Titles data set.  What I did was use R to analyze the dataset, and what I chose to analyze was content type, country of origin, ratings,  and release year.  First, how I loaded the data set into R, I used the read_csv function from the Tidyverse package, but first I ran the code for the tidyverse, then the read_csv function, because the read_csv function does not exist until the tidyverse package is loaded. Then I use the glimpse() function to examine the structure of the data set. This helped me examine the data set better because it included the number of observations, variable names, and data types. After that then I use pipe operator (%>%). The use is to pass the Netflix data set through a sequence of data cleaning and summarization steps, with the final results stored in a new data set, which I called it movievsshows_count. Then kept analyzing the number of movies and TV shows on netflix and I calculated it by using function count(type), and the values in the type column. No missing values were removed for the step, and I chose that because the type variable contains complete information for all titles. As well, the results for that were movies on netflix was 6,131, and TV shows were 2,676.

After that, I made a list of which countries produce the most netflix content and did a top 10. Rows with missing country values are removed. I first used the pipe operator (%>%). Again, the use is to pass the netflix data set through a sequence of data cleaning and summarization steps, with the final results stored in a new data set, which I called it country_count. I use the filter()  function to keep only rows that meet the condition and that ones did not have missing country values, and the other function was !is.na(country), and I use this code because it means keep rows where country is not missing. Because some titles list multiple countries in a single cell, so these entries are split into separate rows to ensure each country is counted individually. Now, the results are sorted to identify the top producing countries. For the Results 1. United States: 3,689, 2. India: 1,046, 3. United Kingdom: 804, and after that, the results were about 450 or lower than for the last 7. 


This code here analyzes the distribution of netflix content ratings using the rating column. As well, similar to the code for which countries produce the most netflix content. We started with using the pipe operator and named it rate_count, then used the filter function, then used!is na to remove rows with where the ratings are missing and also filtered out incorrect entries that contain duration values like 66 min, for example. After cleaning the data, it counts how many titles fall into each valid rating category, such as TV-MA, PG-13, or TV-14. The results show that the top 3 were, number 1 TV-MA: 3,207, 2 TV-14: 2,160, 3 TV-PG: 863, and then after that last 11 ratings were 800 or less. Last thing I coded was a line chart and I use the ggplot2  package to make a visualization trend in netflix content over time. For year_count That data set is used where release_year  is on the x-axis and n( the number of titles release that year) is on the y-axis. Then I use the geom_line() function and that draws a line connecting the number of tiles for each year, and that shows me how content production has changed over time. The labs()  function adds a descriptive title and axis label to make the chart more easier to understand. The results show on line chart that there were very few titles before the 2000s, but there was a slow growth from 2000 to 2010, and then there was a good amount of increase after 2010, and that shows Netflix's expansion in original content. 
